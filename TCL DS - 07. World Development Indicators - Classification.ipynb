{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with World Development Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workbook we will load up the World Development Indicators data set and take it through the process of building a classification model to predict life expectancy band - L, M or H - for countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load the libraries we need.  For this course we will use this library, which combines the components we need from Numpy, Pandas, Matplotlib and Scikit Learn an wraps then in a simplified class called a DasiFrame.  DasiFrame is essentially a Pandas DataFrame extended with machine learning capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dasi_library import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data from the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = readCsv('World Indicators 2000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will poke around the data to see what we can find.  The aim is to understand the data a bit more whilst wearing our machine learning hat.  We want to understand the features and identify which features might be useful for us when training our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the number of features (columns) and samples (rows)\n",
    "Understand the size of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have a quick look at the data\n",
    "Take a quick look at the data to understand what you are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate descriptive stats\n",
    "These give an idea of the range and spread of values for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical visualisation\n",
    "We can gain a better understanding of the data using some visualisations.  \n",
    "\n",
    "### Box plots\n",
    "Box plots give an idea of spread.\n",
    "\n",
    "\n",
    "<hr/>\n",
    "\n",
    "**Question: >>**\n",
    "\n",
    "**Run the box plots below.  What do these box plots tell you about the individual features?**\n",
    "<hr/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boxPlotAll(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms\n",
    "Histograms give an idea of distribution.\n",
    "\n",
    "\n",
    "<hr/>\n",
    "\n",
    "**Question: >>**\n",
    "\n",
    "**Run the histogram plot below.  What do these histograms tell you about the individual features?**\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histPlotAll(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix\n",
    "\n",
    "A correlation matrix allows you to quickly see the extent to which there are correlations (positive or negative) between pairs of attributes.  Dark blues and bright yellows are a good sign.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "**Question: >>**\n",
    "\n",
    "**Run the correlation matrix below.  Which pairs of features are most interesting as predictors of LifeExp?**\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationMatrix(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "\n",
    "### Remove identifiers (i.e. anything that is not a feature)\n",
    "\n",
    "We will remove the country name as it is not used for creating the model and will get in the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = removeCol(dataset, 'CountryName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Add additional derived features we may need\n",
    "\n",
    "We may want to derive new features from existing features.  For example, here we will band the life expectancy into L, M and H."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = appendClass(dataset, 'LifeExpBand','LifeExp',[0,50,60,100],['L','M','H'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just quickly check this worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selectCols(dataset, ['LifeExpBand','LifeExp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select our target feature\n",
    "\n",
    "For a classification task, the target feature is a feature with 2 or more unique values.  Here we will select the LifeExpBand that we just created.  Our aim with the model is to predict the LifeExpBand based on other features.  In other words, we want to build a model that uses a few key features to predict the life expectancy (L, M, H) in a country.\n",
    "\n",
    "Let's check how many countries are in each band:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classDistribution(dataset, 'LifeExpBand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bands are a little unbalanced, so training may not be great.  Let's make some adjustments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = appendClass(dataset, 'LifeExpBand','LifeExp',[0,65,73,100],['L','M','H'])\n",
    "classDistribution(dataset, 'LifeExpBand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a bit better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect some more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how each feature compares for each life expectancy band.  This is really useful - we can already visually see which features might be selected.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "**Question: >>**\n",
    "\n",
    "**Run the class compare plot below.  Look at the separation into L, M and H distributions.  What does each chart tell you about that feature's ability to classify countries into L, M and H life expectancy bands?**\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classComparePlot(dataset, 'LifeExpBand', 'density')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out the target feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By convention, Y is the set of target values for the samples.  These are the values we hope our model will be able to predict.X is the set of input samples, which we will use to make our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = splitXY(dataset, 'LifeExpBand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process and select the best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will rescale all features to have values between 0 and 1.  This helps some algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rescale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, rather than doing this manually, we will use statistics to find the 4 features that best contribute to the target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = selectFeaturesKBestClassification(4, X, Y)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plot to check our features\n",
    "Let's just have a quick look at a scatter plot to see how the SelectKBest algorithm did.  Scatter plot matrices show how pairs of features are related.  It is useful for seeing correlations between pairs of features.  Because we got the machine learning tools to select the features, we'd hope to see correlations to our target feature.\n",
    "\n",
    "\n",
    "<hr/>\n",
    "\n",
    "**Question: >>**\n",
    "\n",
    "**Do you think SelectKBest has made good choices here?**\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = listColumns(X)+['LifeExp']\n",
    "scatterMatrix(selectCols(dataset, cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and test sets\n",
    "\n",
    "Now split the data set into a training set (67%) and a test set (33%):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = trainTestSplit(X, Y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we will take a different approach.  Rather than just choosing a particular algorithm, we will evaluate a bunch of algorithms to see which one performs the best with this data set.  \n",
    "\n",
    "The evaluateAlgorithmsClassification function creates multiple train / test splits (called **folds**), creates models using all of the algorithms against all of the folds, and returns the results.  The process of using folds in this way is called **k-fold cross-validation**. \n",
    "\n",
    "<hr/>\n",
    "\n",
    "**Question: >>**\n",
    "\n",
    "**What improvement do you think we get by creating multiple models with multiple train/test splits?  Think about the variance in results that we saw when we changed the random seed in the previous model building we did.**\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "algorithms = []\n",
    "algorithms.append(LogisticRegression)\n",
    "algorithms.append(LinearDiscriminantAnalysis)\n",
    "algorithms.append(KNeighborsClassifier)\n",
    "algorithms.append(DecisionTreeClassifier)\n",
    "algorithms.append(GaussianNB)\n",
    "algorithms.append(SVC)\n",
    "evaluateAlgorithmsClassification(X_train, Y_train, algorithms, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have multiple models for each algorithm, we have multiple scores for each algorithm.  The value returned above is the mean of all these scores.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now take our best algorithm and create a model using all of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modelFit(X_train, Y_train, LogisticRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our model using the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(model, X_train)\n",
    "print(accuracy_score(Y_train, predictions))\n",
    "print(confusion_matrix(Y_train, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the model to make predictions on data that was not used for training:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do a final test of the model against the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(model, X_test)\n",
    "print(accuracy_score(Y_test, predictions))\n",
    "print(confusion_matrix(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also join the predictions to the data set and correct values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparePredictionsWithOriginals(X_test, predictions, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Apply the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now see if you can apply the model to the World Indicators 2010 data, to see if our model based on 2000 data holds for 2010 figures.\n",
    "\n",
    "Work through the following, replacing the ## marked items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the world indicators 2010 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_dataset = readCsv('##NAME OF YOUR CSV FILE##')\n",
    "unseen_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the LifeExpBand class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_dataset = unseen_dataset.appendClass(\n",
    "    class_name='##Name of your target feature##',\n",
    "    feature='##Name of the unbanded target feature##',\n",
    "    thresholds=[##List of thresholds##],\n",
    "    names=[##List of band names##])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what the distribution is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_dataset.classDistribution(class_name='##Name of your target feature##')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select just the columns we used in our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.listColumns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_dataset = unseen_dataset.selectCols([##names of your input and target features##])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into target feature and input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = unseen_dataset.splitXY('##Name of your target feature##')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.rescale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use our model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.comparePredictionsWithOriginals(predictions, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(Y, predictions))\n",
    "print(confusion_matrix(Y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
